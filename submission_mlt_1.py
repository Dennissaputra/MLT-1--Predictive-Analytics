# -*- coding: utf-8 -*-
"""submission - MLT 11

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1L0yaD1Lx7gfHp5G2QrJdR4P6-zJpkWmc
"""

# import api kaggle
from google.colab import files
uploaded=files.upload()

!rm -rf ~/.kaggle && mkdir ~/.kaggle/
!mv kaggle.json ~/.kaggle/kaggle.json
!chmod 600 ~/.kaggle/kaggle.json

# download dataset
!kaggle datasets download -d fedesoriano/stroke-prediction-dataset

!unzip /content/stroke-prediction-dataset.zip

"""#import library"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
# %matplotlib inline
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn.tree  import DecisionTreeClassifier
from sklearn.metrics import confusion_matrix, classification_report

"""#data frame"""

# Membaca file csv
df = pd.read_csv('healthcare-dataset-stroke-data.csv')
df

# menghapus id
df = df.drop(['id'], axis=1)

# cek jumlah dataframe
df.shape

# cek informasi tentang dataframe
df.info()

# mengubah tipe data int ke object
df['hypertension'] = df['hypertension'].astype('object')
df['heart_disease'] = df['heart_disease'].astype('object')

# mengubah tipe data stroke dari int ke object karena class target 
df['stroke'] = df['stroke'].astype('object')

df.stroke.replace(0,'Tidak mengalami Stroke', inplace=True)
df.stroke.replace(1,'Mengalami Stroke', inplace=True)

# Mendeskripsikan statistik
df.describe()

# mengecek informasi yang di mmuat pada dataset
def report(df):
  col = []
  d_type = []
  uniques = []
  n_uniques = []

  for i in df.columns:
    col.append(i) 
    d_type.append(df[i].dtypes) 
    uniques.append(df[i].unique()[:5]) 
    n_uniques.append(df[i].nunique()) 

  return pd.DataFrame({'Column': col, 'd_type':d_type, 'unique_sample':uniques, 'n_unique_sample':n_uniques})

report(df)

"""#menghilangkan missing value"""

# cek missing value
df.isnull().sum()

# Mengreplace missing value pada BMI
df.bmi = df.bmi.fillna(df.bmi.mean())
df.head()

# Melakukan visualisasi data yang kosong
import missingno as msno
sorted_null = msno.nullity_sort(df, sort='descending') 
figures = msno.matrix(sorted_null, color=(1, 0.43, 0.43))

"""#univariat analysis"""

#membagi fitur pada dataset 
cat_features = ["gender", "hypertension", "heart_disease", "ever_married", "work_type", "Residence_type",
                "smoking_status","stroke"]
numerical_features = ["age", "avg_glucose_level", "bmi"]

#melihar kategori fitur kategori
for column in cat_features:
    count = df[column].value_counts()
    percent = 100*df[column].value_counts(normalize=True)
    data_baru = pd.DataFrame({'Total ':count, 'Persentase':percent.round(1)})
    print(data_baru, end="\n\n")
    count.plot(kind='bar', title=column)
    plt.show()

"""#menganalisis outliers"""

# melihat outlier pada numeric fitur
fig, axs = plt.subplots(len(numerical_features), figsize= (15,10))
i=0
for feature in numerical_features:
  sns.boxplot(df[feature], ax=axs[i])
  i+=1
  plt.tight_layout()
plt.show()

# menghapus outliers menggunakan IQR
Q1 = df.quantile(0.25)
Q3 = df.quantile(0.75)
IQR=Q3-Q1
df=df[~((df<(Q1-1.5*IQR))|(df>(Q3+1.5*IQR))).any(axis=1)]
 
# Cek ukuran dataset setelah kita drop outliers
df.shape

#hasil sesudah di drop outlier menggunakan IQR
fig, axs = plt.subplots(len(numerical_features), figsize= (15,10))
i=0
for feature in numerical_features:
  sns.boxplot(df[feature], ax=axs[i])
  i+=1
  plt.tight_layout()
plt.show()

"""#fitur numerik"""

# melihat numerik fitur
df.hist(bins=50, figsize=(15,10))
plt.show()

# Mengamati hubungan antar fitur numerik dengan fungsi pairplot()
sns.pairplot(df, diag_kind = 'kde')

#evaluasi skor korelasi
plt.figure(figsize=(15,15))
plt.title('Matriks Korelasi untuk Fitur Numerik', fontsize=9)
sns.heatmap(df.corr(), annot=True, cmap='coolwarm', vmin=-1, vmax=1)
plt.show()

"""#Data Preparation"""

# Encoding tanpa variabel dependent sebagai variabel target
df = pd.get_dummies(df, columns=df.loc[:, (df.dtypes == 'object') & (df.columns != 'stroke')].columns.to_list())

# hasil setelah encoding
df

# Split data
X = df.drop(["stroke"],axis =1)
y = df["stroke"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 123)

# hasil split data
print(f'Total # of sample in whole dataset: {len(X)}')
print(f'Total # of sample in train dataset: {len(X_train)}')
print(f'Total # of sample in test dataset: {len(X_test)}')

"""#standarisasi"""

# melakukan standarisasi
numerical_features = ["age", "avg_glucose_level", "bmi"]
scaler = StandardScaler()
scaler.fit(X_train[numerical_features])
X_train[numerical_features] = scaler.transform(X_train.loc[:, numerical_features])
X_train[numerical_features].head()

#mengubah rata-rata mean
X_train[numerical_features].describe().round(4)

"""#model development

random forest
"""

# pemodelan menggunakan classification with random forest

rf = RandomForestClassifier(n_estimators = 100, criterion= 'entropy', random_state = 0)
rf.fit(X_train, y_train)

#cek akurasi random forest
y_pred_train_rf = rf.predict(X_train)
acc_train_rf = accuracy_score(y_train, y_pred_train_rf)

y_pred_test_rf = rf.predict(X_test)
acc_test_rf = accuracy_score(y_test, y_pred_test_rf)
print(acc_train_rf)
print(acc_test_rf)

# report klasifikasi untuk model random forest
Random_Forest = classification_report(y_test, y_pred_test_rf, output_dict=True)
pd.DataFrame(Random_Forest)

"""decision tree"""

#pemodelan menggunakan Decision Tree
dt =DecisionTreeClassifier(max_features=14 , max_depth=12, criterion= 'gini')
dt.fit(X_train, y_train)

#cek akurasi model decision tree
y_pred_train_dt = dt.predict(X_train)
acc_train_dt = accuracy_score(y_train, y_pred_train_dt)

y_pred_test_dt = dt.predict(X_test)
acc_test_dt = accuracy_score(y_test, y_pred_test_dt)
print(acc_train_dt)
print(acc_test_dt)

# report klasifikasi untuk model decision tree
Decision_tree = classification_report(y_test, y_pred_test_dt, output_dict=True)
pd.DataFrame(Decision_tree)

# Lakukan scaling terhadap fitur numerik pada X_test sehingga memiliki rata-rata=0 dan varians=1
X_test.loc[:, numerical_features] = scaler.transform(X_test[numerical_features])

"""#evaluasi"""

print("Classification Report untuk Model random forest")
pd.DataFrame(Random_Forest)

print("Classification Report untuk Model decision tree")
pd.DataFrame(Decision_tree)